---
title: "Customer purchasing behavior data analysis with GAM"
author: "Robert A. Stevens"
date: "`r Sys.Date()`"
output: github_document
---

TODO

0. add EDA

1. add checks

2. add residual analysis

3. follow NIST flowchart?

4. Pick best model - start with linear and add splines until too many

5. communicate - ggplot?

```{r, echo=FALSE, messages=TRUE, warning=TRUE}
knitr::opts_chunk$set(comment=NA, echo=TRUE, warning=TRUE, message=TRUE)
```

In the first three chapters, you used GAMs for regression of continuous outcomes. In this chapter, you will use GAMs for classification. You will build logistic GAMs to predict binary outcomes like customer purchasing behavior, learn to visualize this new type of model, make predictions, and learn how to explain the variables that influence each prediction.

## Import

```{r}
# import packages
library(magrittr)
library(mgcv)
library(tibble)
# library(tidyverse)
```

```{r}
# import data
# csale <- readRDS("csale.rds")
csale <- read.csv("csale.csv")
new_credit_data <- read.csv("new_credit_data.csv")
```

```{r}
str(csale)
```

```{r}
# Examine the mpg data frame
head(csale)
```

## Tidy

N/A

## Transform

N/A

## Visualize


## Model


## 4.2 Classifying purchasing behavior

Let's fit some GAMs to the `csale` data, which has the binary `purchase` outcome variable.

After you fit the model, answer the following question:

What does the `log_mod` model estimate the probability of a person making a purchase who has mean values of all variables?

```{r}
# Fit a logistic model
log_mod <- gam(
  purchase ~ s(mortgage_age), 
  data = csale, 
  family = binomial, 
  method = "REML"
)

summary(log_mod)
```

```{r}
plogis(-1.34131)
```

- 7.5%

- 11%

- 21% - Yes

- 72%

*This is the probability when all smooths are at zero and the only effect is the intercept.*

## 4.3 Purchase behavior with multiple smooths

In this exercise, you will fit a logistic GAM that predicts the outcome (`purchase`) in `csale`, using all other variables as predictors.

After summarizing the model, answer the following question:

Which term in the model is significant but approximately linear?

```{r}
# 1/2

# Fit a logistic model
log_mod2 <- gam(
  purchase ~ 
    s(n_acts) + 
    s(bal_crdt_ratio) + 
    s(avg_prem_balance) + 
    s(retail_crdt_ratio) + 
    s(avg_fin_balance) +  
    s(mortgage_age) + 
    s(cred_limit),
  data = csale,
  family = binomial,
  method = "REML"
)

# View the summary
summary(log_mod2)
```

```
# 2/2
```

- `s(n_acts)`

- `s(avg_prem_balance)`

- `s(retail_crdt_ratio)`

- `s(cred_limit)` - Yes

*This term is linear with `edf` near one, and with p < 0.05. These same terms apply in the case of logistic GAMs.*

## 4.5 Visualizing influences on purchase probability

Let's try plotting and interpreting the purchasing behavior model from the last lesson. You'll step through several iterations of plots of `log_mod2`, moving from raw plots on the fitting scale towards plots on the response scale with more natural interpretations.

The model (`log_mod2`) from the previous exercise is available in your workspace.

```{r}
# 1/4

# Plot on the log-odds scale
# plot(log_mod2, pages = 1)
plot(log_mod2)
```

```{r}
# 2/4

# Plot on the probability scale
# plot(log_mod2, pages = 1, trans = plogis)
plot(log_mod2, trans = plogis)
```

```{r}
# 3/4

# Plot with the intercept
# plot(log_mod2, pages = 1, trans = plogis, shift = coef(log_mod2)[1])
plot(log_mod2, trans = plogis, shift = coef(log_mod2)[1])
```

```{r}
# 4/4

# Plot with intercept uncertainty
# plot(log_mod2, pages = 1, trans = plogis, shift = coef(log_mod2)[1], seWithMean = TRUE)
plot(log_mod2, trans = plogis, shift = coef(log_mod2)[1], seWithMean = TRUE)
```

## 4.6 Interpreting purchase effect plots (I)

For the next few questions, you'll inspect the partial effects plots of some of the terms in `log_mod2`.

All else being equal, which of these variables has the largest effect on purchase probability?

- `s(avg_fin_balance)`

- `s(mortage_age)`

- `s(cred_limit)`

- `s(n_acts)` - Yes

## 4.7 Interpreting purchase effect plots (II)

What is the expected purchase probability of a person with 20 accounts (`n_acts` = 20) if all other values are average?

- 0.15

- 0.25

- 0.35

- 0.55 - Yes

## 4.8 Interpreting purchase effect plots (III)

Which of these predictions has the greatest uncertainty, assuming all other variables are at average levels?

- The probability of purchase when `avg_fin_balance` is 2000

- The probability of purchase when `mortgage_age` is 50

- The probability of purchase when `avg_fin_balance` is 5000 - Yes

- The probability of purchase when `mortgage_age` is 150

*There are wide confidence intervals around the `avg_fin_balance` smooth at a value at 5000.*

## 4.9 Making predictions

### `mgcv` `predict()` function

```{r}
predict(log_mod2)[1:8]
```

### Prediction types

```{r}
predict(log_mod2, type = "link")[1:8]
```

```{r}
predict(log_mod2, type="response")[1:8]
```

```{r}
plogis(predict(log_mod2, type="link"))[1:8]
```

### Standard errors

```{r}
predict(log_mod2, type = "link", se.fit = TRUE) %>% as_tibble() %>% head(8)
```

### Explaining predictions by terms

```{r}
predict(log_mod2, type = "terms") %>% as_tibble() %>% head(10)
```

### Explaining predictions by terms (2)

```{r}
predict(log_mod2, type = "terms")[1, ]
```

```{r}
plogis(sum(predict(log_mod2, type = "terms")[1, ]) + coef(log_mod2)[1])
```

## 4.10 Predicting purchase behavior and uncertainty

The `log_mod2` purchase behavior model lets you make predictions off credit data. In this exercise, you'll use a new set of data, `new_credit_data`, and calculate predicted outcomes and confidence bounds.

The model (`log_mod2`) from the exercise 3 is available in your workspace.

```{r}
# 1/3

# Calculate predictions and errors
predictions <- predict(log_mod2, newdata = new_credit_data, type = "link", se.fit = TRUE)

# Inspect the predictions
predictions
```

```{r}
# 2/3

# Calculate predictions and errors
predictions <- predict(log_mod2, newdata = new_credit_data, type = "link", se.fit = TRUE)

# Calculate high and low prediction intervals
high_pred <- predictions$fit + 2*predictions$se.fit
low_pred <- predictions$fit - 2*predictions$se.fit
```

```{r}
# 3/3

# Calculate predictions and errors
predictions <- predict(log_mod2, newdata = new_credit_data, type = "link", se.fit = TRUE)

# Calculate high and low predictions intervals
high_pred <- predictions$fit + 2*predictions$se.fit
low_pred <- predictions$fit - 2*predictions$se.fit

# Convert intervals to probability scale
high_prob <- plogis(high_pred)
low_prob <- plogis(low_pred)

# Inspect
high_prob
```

```{r}
low_prob
```

*See how the range of predictions never fall outside zero and one when you calculate intervals before converting to probability?*

## 4.11 Explaining individual behaviors

In the final exercise of this chapter, you will use the model log_mod2 to predict the contribution of each term to the prediction of one row in new_credit_data.

After predicting, answer the following question: Which term makes the greatest contribution to the prediction of this first data point?

```{r}
# 1/2

# Predict from the model
prediction_1 <- predict(
  log_mod2, 
  newdata = new_credit_data[1, ], 
  type = "terms"
)

# Inspect
prediction_1
```

```
# 2/2
```

- `s(n_acts)`

- `s(bal_crdt_ratio)` - Yes

- `s(avg_prem_balance)`

- `s(retail_crdt_ratio)`

*For this data point, `s(bal_crdt_ratio)` has the greatest contribution to the prediction. Note this is despite the fact that `s(n_acts)` has a larger overall effect, as we saw in the last section.*

## Communicate

